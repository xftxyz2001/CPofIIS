{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入了一些常用的数据处理库和函数，为后续的数据加载和数据增强做准备。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # 用于科学计算\n",
    "from batchgenerators.dataloading.data_loader import DataLoader  # 用于加载训练数据和标签数据\n",
    "from batchgenerators.transforms.abstract_transforms import Compose  # 用于将多个数据变换组合在一起\n",
    "from batchgenerators.transforms.spatial_transforms import (\n",
    "    MirrorTransform,  # 镜像变换（左右镜像、上下镜像）\n",
    "    SpatialTransform,  # 空间变换（旋转、缩放、平移）\n",
    ")\n",
    "from batchgenerators.transforms.color_transforms import (\n",
    "    BrightnessMultiplicativeTransform,  # 亮度变换（乘性）\n",
    "    ContrastAugmentationTransform,  # 对比度变换（增强）（线性）（非线性）\n",
    ")\n",
    "from batchgenerators.transforms.noise_transforms import (\n",
    "    GaussianNoiseTransform,  # 高斯噪声变换\n",
    "    GaussianBlurTransform,  # 高斯模糊变换\n",
    ")\n",
    "from batchgenerators.augmentations.crop_and_pad_augmentations import crop  # 裁剪和填充变换"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义函数 `get_split_fold` 接收一个 csv 文件的数据，该数据集已按照交叉验证的折叠进行了拆分，其中训练集为第 0 折，测试集 A 为第 1 折，测试集 B 为第 2 折。函数通过查找 \"fold\" 列的值来确定每个数据点所属的数据集，然后返回一个包含训练、测试 A 和测试 B 数据集的字典。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_fold(data):\n",
    "    \"\"\"\n",
    "    如果数据集已经按照 [0,1,2] 分成了三个数据集\n",
    "    其中:\n",
    "    - 训练集 => 0\n",
    "    - 测试集A => 1\n",
    "    - 测试集B => 2\n",
    "    @param data: 存储数据集的 CSV 文件\n",
    "    @return: 训练集，测试集A，测试集B 的字典\n",
    "    \"\"\"\n",
    "    # 折叠数据的返回索引\n",
    "    train_idx = np.where(data[\"fold\"] == 0)[0]\n",
    "    testA_idx = np.where(data[\"fold\"] == 1)[0]\n",
    "    testB_idx = np.where(data[\"fold\"] == 2)[0]\n",
    "\n",
    "    # 为每个数据集创建字典\n",
    "    train_ds = {\n",
    "        \"img_npy\": [data[\"img_npy\"].tolist()[i] for i in train_idx],\n",
    "        \"anno_npy\": [data[\"anno_npy\"].tolist()[i] for i in train_idx],\n",
    "        \"patient_id\": [data[\"patient ID\"].tolist()[i] for i in train_idx],\n",
    "    }\n",
    "    testA_ds = {\n",
    "        \"img_npy\": [data[\"img_npy\"].tolist()[i] for i in testA_idx],\n",
    "        \"anno_npy\": [data[\"anno_npy\"].tolist()[i] for i in testA_idx],\n",
    "        \"patient_id\": [data[\"patient ID\"].tolist()[i] for i in testA_idx],\n",
    "    }\n",
    "    testB_ds = {\n",
    "        \"img_npy\": [data[\"img_npy\"].tolist()[i] for i in testB_idx],\n",
    "        \"anno_npy\": [data[\"anno_npy\"].tolist()[i] for i in testB_idx],\n",
    "        \"patient_id\": [data[\"patient ID\"].tolist()[i] for i in testB_idx],\n",
    "    }\n",
    "\n",
    "    return {\"train_ds\": train_ds, \"testA_ds\": testA_ds, \"testB_ds\": testB_ds}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义函数 `get_train_transform(patch_size, prob)` ，参数1为输入图像的大小，输入2为变换的概率。该函数返回一个数据增强的变换列表，这些变换用于增强神经网络模型训练数据。这里采用的数据增强方法包括：弹性变形、镜像变换、亮度调整、高斯噪声、高斯模糊和对比度增强。其中弹性变形可以减少数据集的大小，并且不会引入边界伪影。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_transform(patch_size, prob=0.5):\n",
    "    tr_transforms = []  # 创建一个空列表，用于存储变换\n",
    "    # 使用SpatialTransform进行空间变换\n",
    "    tr_transforms.append(\n",
    "        SpatialTransform(\n",
    "            patch_size,  # 输入图像的大小\n",
    "            [i // 2 for i in patch_size],  # 中心点\n",
    "            do_elastic_deform=True,  # 弹性变形\n",
    "            alpha=(0.0, 300.0),  # 弹性变形的强度\n",
    "            sigma=(20.0, 40.0),  # 弹性变形的平滑度\n",
    "            do_rotation=True,  # 旋转\n",
    "            angle_x=(-np.pi / 15.0, np.pi / 15.0),  # 旋转角度\n",
    "            angle_y=(-np.pi / 15.0, np.pi / 15.0),  # 旋转角度\n",
    "            angle_z=(0.0, 0.0),  # 旋转角度\n",
    "            do_scale=True,  # 缩放\n",
    "            scale=(1 / 1.15, 1.15),  # 缩放比例\n",
    "            random_crop=False,  # 随机裁剪\n",
    "            border_mode_data=\"constant\",  # 边界模式：常数\n",
    "            border_cval_data=0,  # 边界值\n",
    "            order_data=3,  # 数据的阶数\n",
    "            p_el_per_sample=prob,  # 弹性变形的概率\n",
    "            p_rot_per_sample=prob,  # 旋转的概率\n",
    "            p_scale_per_sample=prob,  # 缩放的概率\n",
    "        )\n",
    "    )\n",
    "    # 使用MirrorTransform进行镜像变换，这里只进行左右镜像\n",
    "    tr_transforms.append(MirrorTransform(axes=(1,)))\n",
    "    # 使用BrightnessMultiplicativeTransform对图像的亮度进行调整\n",
    "    tr_transforms.append(\n",
    "        # 下面的三个参数分别是：亮度的乘性因子，是否对每个通道进行变换，每个样本的变换概率\n",
    "        BrightnessMultiplicativeTransform(\n",
    "            (0.7, 1.5), per_channel=True, p_per_sample=prob\n",
    "        )\n",
    "    )\n",
    "    # 使用GaussianNoiseTransform对图像添加高斯噪声，噪声的方差在 [0, 0.5] 之间\n",
    "    tr_transforms.append(\n",
    "        GaussianNoiseTransform(noise_variance=(0, 0.5), p_per_sample=prob)\n",
    "    )\n",
    "    # 使用GaussianBlurTransform对图像进行高斯模糊，模糊的程度在 [0.5, 2.0] 之间\n",
    "    tr_transforms.append(\n",
    "        GaussianBlurTransform(\n",
    "            blur_sigma=(0.5, 2.0),\n",
    "            different_sigma_per_channel=True,\n",
    "            p_per_channel=prob,\n",
    "            p_per_sample=prob,\n",
    "        )\n",
    "    )\n",
    "    # 使用ContrastAugmentationTransform对图像进行对比度增强，增强的程度在 [0.75, 1.25] 之间\n",
    "    tr_transforms.append(\n",
    "        ContrastAugmentationTransform(contrast_range=(0.75, 1.25), p_per_sample=prob)\n",
    "    )\n",
    "    # 使用Compose将这些变换组合在一起\n",
    "    tr_transforms = Compose(tr_transforms)\n",
    "    return tr_transforms  # 返回变换"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "继承 `batchgenerators.dataloading.data_loader.DataLoader` 定义自己的 `DataLoader` 类，用于加载训练数据，并生成训练批次。构造函数接收训练数据、批量大小、裁剪大小、线程数量等参数，并可选择是否启用数据洗牌、数据增强等功能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader(DataLoader):  # batchgenerators.dataloading.data_loader.DataLoader\n",
    "    def __init__(\n",
    "        self,\n",
    "        data,  # 数据集：必须是由get_list_of_patients返回的患者列表（并由get_split_deterministic拆分）\n",
    "        batch_size,  # 批次大小\n",
    "        patch_size,  # 批具有的空间大小\n",
    "        num_threads_in_multithreaded,  # 多线程\n",
    "        crop_status=False,  # 是否裁剪：默认不裁剪\n",
    "        crop_type=\"center\",  # 裁剪类型：中心裁剪\n",
    "        seed_for_shuffle=1234,  # 随机种子\n",
    "        return_incomplete=False,  # 默认不返回不完整的批次\n",
    "        shuffle=True,  # 默认打乱\n",
    "        infinite=True,  # 默认无限循环\n",
    "        margins=(0, 0, 0),  # 边距0\n",
    "    ):\n",
    "        super().__init__(\n",
    "            data,\n",
    "            batch_size,\n",
    "            num_threads_in_multithreaded,\n",
    "            seed_for_shuffle,\n",
    "            return_incomplete,\n",
    "            shuffle,\n",
    "            infinite,\n",
    "        )\n",
    "        self.patch_size = patch_size  # 批具有的空间大小\n",
    "        self.n_channel = 3  # 通道数\n",
    "        self.indices = list(range(len(data[\"img_npy\"])))  # 索引\n",
    "        self.crop_status = crop_status  # 是否裁剪\n",
    "        self.crop_type = crop_type  # 裁剪类型\n",
    "        self.margins = margins  # 边距\n",
    "\n",
    "    @staticmethod  # 静态方法：加载患者\n",
    "    def load_patient(img_path):\n",
    "        img = np.load(img_path, mmap_mode=\"r\")  # 以只读模式加载图像\n",
    "        return img\n",
    "\n",
    "    def generate_train_batch(self):\n",
    "        idx = self.get_indices()  # 调用父类的方法获取下一个批次中要使用的病人的索引\n",
    "        gland_img = [self._data[\"img_npy\"][i] for i in idx]  # 根据索引获取数据图像\n",
    "        img_seg = [self._data[\"anno_npy\"][i] for i in idx]  # 根据索引获取标注图像\n",
    "        patient_id = [self._data[\"patient_id\"][i] for i in idx]  # 根据索引获取病人ID\n",
    "        # 初始化空数组用于存储数据和标注\n",
    "        img = np.zeros(\n",
    "            (len(gland_img), self.n_channel, *self.patch_size), dtype=np.float32\n",
    "        )\n",
    "        seg = np.zeros(\n",
    "            (len(img_seg), self.n_channel, *self.patch_size), dtype=np.float32\n",
    "        )\n",
    "        # 迭代patients_for_batch并将其包含在批次中\n",
    "        for i, (j, k) in enumerate(zip(gland_img, img_seg)):\n",
    "            img_data = self.load_patient(j)  # 加载数据图像\n",
    "            seg_data = self.load_patient(k)  # 加载标注图像\n",
    "            # 根据文档要求，输入图像应该以通道为首的顺序输入，因此我们使用张量操作来转换为通道为首的格式\n",
    "            img_data = np.einsum(\"hwc->chw\", img_data)\n",
    "            seg_data = np.einsum(\"hwc->chw\", seg_data)\n",
    "            # 现在随机裁剪到self.patch_size大小\n",
    "            # crop期望数据为(b, c, x, y, z)，但patient_data的形状为(c, x, y, z)，因此我们需要添加一个虚拟维度，以便它能够工作（@Todo，可以改进）\n",
    "            if self.crop_status:\n",
    "                img_data, seg_data = crop(\n",
    "                    img_data[None],\n",
    "                    seg=seg_data[None],\n",
    "                    crop_size=self.patch_size,\n",
    "                    margins=self.margins,\n",
    "                    crop_type=self.crop_type,\n",
    "                )\n",
    "                img[i] = img_data[0]\n",
    "                seg[i] = seg_data[0]\n",
    "            else:\n",
    "                img[i] = img_data\n",
    "                seg[i] = seg_data\n",
    "        return {\"data\": img, \"seg\": seg, \"patient_id\": patient_id}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义一系列工具函数，用于图像处理和分割。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入matplotlib和skimage模块以支持图像处理和分割。\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import color\n",
    "from skimage import segmentation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义函数 plot_comparison 用于绘制多个图像的比较，但仅在列方向上进行。输入参数包括图像列表、标题列表、行数、列数、绘图标识、保存路径等。如果绘图标识为True，函数将绘制图像；否则，它将返回一个图像对象。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparison(\n",
    "    input_img,  # 输入图像\n",
    "    caption=None,  # 标题\n",
    "    plot=True,  # 是否绘制\n",
    "    save_path=None,  # 保存路径\n",
    "    save_name=None,  # 保存名称\n",
    "    save_as=\"png\",  # 保存格式\n",
    "    save_dpi=300,  # 保存分辨率\n",
    "    captions_font=20,  # 标题字体大小\n",
    "    n_row=1,  # 行数\n",
    "    n_col=2,  # 列数\n",
    "    figsize=(5, 5),  # 图像大小\n",
    "    cmap=\"gray\",  # 颜色映射：灰度\n",
    "):\n",
    "    print()\n",
    "    if caption is not None:\n",
    "        assert len(caption) == len(\n",
    "            input_img\n",
    "        ), \"Caption length and input image length does not match\"\n",
    "    assert len(input_img) == n_col, \"Error of input images or number of columns!\"\n",
    "\n",
    "    fig, axes = plt.subplots(n_row, n_col, figsize=figsize)\n",
    "    fig.subplots_adjust(hspace=0.4, wspace=0.4, right=0.7)\n",
    "\n",
    "    for i in range(n_col):\n",
    "        axes[i].imshow(np.squeeze(input_img[i]), cmap=cmap)\n",
    "        if caption is not None:\n",
    "            axes[i].set_xlabel(caption[i], fontsize=captions_font)\n",
    "        axes[i].set_xticks([])\n",
    "        axes[i].set_yticks([])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path + \"{}.{}\".format(save_name, save_as), save_dpi=save_dpi)\n",
    "    if plot:\n",
    "        plt.show()\n",
    "    else:\n",
    "        return fig"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义函数 plot_hist 用于绘制两个图像的直方图，这两个图像在同一行中，并且标题显示在图像下方。输入参数包括图像列表、标题列表、行数、列数、bin数、像素值范围等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(\n",
    "    inp_img, titles, n_row=1, n_col=2, n_bin=20, ranges=[0, 1], figsize=(5, 5)\n",
    "):\n",
    "    \"\"\"输入图像的绘制直方图\n",
    "    Args:\n",
    "        inp_img (_type_): 图像列表\n",
    "        titles (_type_): 标题列表\n",
    "        n_row (int, optional): 行数\n",
    "        n_col (int, optional): 列数\n",
    "        n_bin (int, optional): bin数\n",
    "        ranges (list, optional): 范围\n",
    "        figsize (tuple, optional): 图像大小\n",
    "    \"\"\"\n",
    "    assert len(titles) == len(\n",
    "        inp_img\n",
    "    ), \"Caption length and input image length does not match\"\n",
    "    assert len(inp_img) == n_col, \"Error of input images or number of columns!\"\n",
    "\n",
    "    fig, axes = plt.subplots(n_row, n_col, figsize=figsize)\n",
    "    fig.subplots_adjust(hspace=0.4, wspace=0.4, right=0.7)\n",
    "\n",
    "    for i in range(n_col):\n",
    "        inp = np.squeeze(inp_img[i])\n",
    "        axes[i].hist(inp.ravel(), n_bin, ranges)\n",
    "        axes[i].set_title(titles[i])\n",
    "        axes[i].set_xlabel(\"Pixel Value\")\n",
    "        axes[i].set_ylabel(\"Frequency\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义函数 overlay_mask 将分割掩模覆盖在原始图像上。输入参数包括图像、分割掩模、颜色和掩模不透明度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_mask(image, mask, colors=[(0, 1.0, 0)], alpha=0.12):\n",
    "    # 图像归一化\n",
    "    if np.max(image) > 1.0:\n",
    "        image = image / 255.0\n",
    "    # 灰度图像\n",
    "    if mask.ndim == 3:\n",
    "        mask = mask[:, :, 0]\n",
    "    mask_image = color.label2rgb(mask, image, colors=colors, alpha=alpha, bg_label=0)\n",
    "    return mask_image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "overlay_boundary 函数在原始图像上绘制分割边界线。输入参数包括图像、分割掩模、颜色和边界线模式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_boundary(image, mask, color=(0, 1.0, 0), mode=\"thick\"):\n",
    "    if np.max(image) > 1.0:\n",
    "        image = image / 255.0\n",
    "    if mask.ndim == 3:\n",
    "        mask = mask[:, :, 0]\n",
    "    boundary_image = segmentation.mark_boundaries(image, mask, color=color, mode=mode)\n",
    "    return boundary_image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot_labels_color 通过循环使用matplotlib定义的颜色映射可视化分割标签。输入参数包括标签、颜色映射等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_labels_color(label_im, cmap=\"tab20c\"):\n",
    "    # 构造彩色图像以叠加\n",
    "    color_mask = np.zeros(label_im.shape)\n",
    "    get_cmap = plt.cm.get_cmap(cmap)\n",
    "    # 循环通过cmap为每种颜色是相关联的标签\n",
    "    for i in range(np.max(label_im)):\n",
    "        color_mask[label_im[:, :, 0] == i + 1] = list(get_cmap(i))[:-1]\n",
    "    return color_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用于输入图像的通道方向最小最大归一化\n",
    "def min_max_norm(img, axis=(1, 2)):\n",
    "    inp_shape = img.shape\n",
    "    img_min = np.broadcast_to(img.min(axis=axis, keepdims=True), inp_shape)\n",
    "    img_max = np.broadcast_to(img.max(axis=axis, keepdims=True), inp_shape)\n",
    "    x = (img - img_min) / (img_max - img_min + float(1e-18))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Software\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import os\n",
    "import pandas as pd\n",
    "from batchgenerators.dataloading.multi_threaded_augmenter import (\n",
    "    MultiThreadedAugmenter,\n",
    ")  # 多线程数据增强数据加载器\n",
    "import wandb\n",
    "from tqdm import tqdm  # 显示进度条\n",
    "import torch  # PyTorch深度学习库\n",
    "from torch import nn  # 神经网络模块\n",
    "import segmentation_models_pytorch as smp  # 用于图像分割的PyTorch中的模型\n",
    "from torchsummary import summary  # 打印模型概要信息\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 忽略Python警告，以确保代码更加简洁、可读和易于维护。\n",
    "2. 使用WandB库初始化一个新的项目并将其与Gland_Seg项目中的glaseg实体关联起来。\n",
    "3. 从指定的CSV文件中读取数据，并将其转化为数据集字典形式。\n",
    "4. 根据配置文件中指定的参数，获取patch_size、batch_size和epochs。\n",
    "5. 获取训练数据集的数据增强变换和使用MultiThreadedAugmenter类对数据进行扩增。\n",
    "6. 使用DataLoader类对训练集和验证集进行分批处理，设置batch_size、patch_size、num_threads_in_multithreaded等参数，并使用了pin_memory=False命令禁用固定内存功能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mxftxyz2001\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\25810\\Desktop\\Gland-Segmentation-main\\wandb\\run-20230505_160330-9c5eqp8w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/xftxyz2001/Gland_Seg/runs/9c5eqp8w' target=\"_blank\">legendary-jawa-20</a></strong> to <a href='https://wandb.ai/xftxyz2001/Gland_Seg' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/xftxyz2001/Gland_Seg' target=\"_blank\">https://wandb.ai/xftxyz2001/Gland_Seg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/xftxyz2001/Gland_Seg/runs/9c5eqp8w' target=\"_blank\">https://wandb.ai/xftxyz2001/Gland_Seg/runs/9c5eqp8w</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "# wandb.init(project=\"Gland_Seg\", entity=\"glaseg\", config=\"config/config.yaml\")\n",
    "wandb.init(project=\"Gland_Seg\", config=\"config/config.yaml\")\n",
    "config = wandb.config\n",
    "tabular_data = pd.read_csv(config.csv)\n",
    "ds_dict = get_split_fold(tabular_data)\n",
    "patch_size = eval(config.patch_size)\n",
    "batch_size = config.batch_size\n",
    "epochs = config.epochs\n",
    "tr_transforms = get_train_transform(patch_size, prob=config.aug_prob)\n",
    "train_dl = DataLoader(\n",
    "    data=ds_dict[\"train_ds\"],\n",
    "    batch_size=batch_size,\n",
    "    patch_size=patch_size,\n",
    "    num_threads_in_multithreaded=4,\n",
    "    seed_for_shuffle=5243,\n",
    "    return_incomplete=False,\n",
    "    shuffle=True,\n",
    "    infinite=True,\n",
    ")\n",
    "train_gen = MultiThreadedAugmenter(\n",
    "    train_dl,\n",
    "    tr_transforms,\n",
    "    num_processes=4,\n",
    "    num_cached_per_queue=2,\n",
    "    seeds=None,\n",
    "    pin_memory=False,\n",
    ")\n",
    "val_dl = DataLoader(\n",
    "    data=ds_dict[\"testA_ds\"],\n",
    "    batch_size=batch_size,\n",
    "    patch_size=patch_size,\n",
    "    num_threads_in_multithreaded=1,\n",
    "    seed_for_shuffle=5243,\n",
    "    return_incomplete=False,\n",
    "    shuffle=True,\n",
    "    infinite=True,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 使用 `smp.Unet` 模型定义一个深度学习模型，并配置所需参数，然后定义一个优化器并指定学习率。\n",
    "2. 定义一个学习率调度器，用于在训练过程中动态调整学习率。（调度器在验证集上监测到模型性能没有提高时，就将学习率减少一个倍数。）\n",
    "3. 使用标签平滑技术定义一个损失函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 256, 256]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 256, 256]             128\n",
      "              ReLU-3         [-1, 64, 256, 256]               0\n",
      "         MaxPool2d-4         [-1, 64, 128, 128]               0\n",
      "            Conv2d-5         [-1, 64, 128, 128]          36,864\n",
      "       BatchNorm2d-6         [-1, 64, 128, 128]             128\n",
      "              ReLU-7         [-1, 64, 128, 128]               0\n",
      "            Conv2d-8         [-1, 64, 128, 128]          36,864\n",
      "       BatchNorm2d-9         [-1, 64, 128, 128]             128\n",
      "             ReLU-10         [-1, 64, 128, 128]               0\n",
      "       BasicBlock-11         [-1, 64, 128, 128]               0\n",
      "           Conv2d-12         [-1, 64, 128, 128]          36,864\n",
      "      BatchNorm2d-13         [-1, 64, 128, 128]             128\n",
      "             ReLU-14         [-1, 64, 128, 128]               0\n",
      "           Conv2d-15         [-1, 64, 128, 128]          36,864\n",
      "      BatchNorm2d-16         [-1, 64, 128, 128]             128\n",
      "             ReLU-17         [-1, 64, 128, 128]               0\n",
      "       BasicBlock-18         [-1, 64, 128, 128]               0\n",
      "           Conv2d-19          [-1, 128, 64, 64]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 64, 64]             256\n",
      "             ReLU-21          [-1, 128, 64, 64]               0\n",
      "           Conv2d-22          [-1, 128, 64, 64]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 64, 64]             256\n",
      "           Conv2d-24          [-1, 128, 64, 64]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 64, 64]             256\n",
      "             ReLU-26          [-1, 128, 64, 64]               0\n",
      "       BasicBlock-27          [-1, 128, 64, 64]               0\n",
      "           Conv2d-28          [-1, 128, 64, 64]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 64, 64]             256\n",
      "             ReLU-30          [-1, 128, 64, 64]               0\n",
      "           Conv2d-31          [-1, 128, 64, 64]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 64, 64]             256\n",
      "             ReLU-33          [-1, 128, 64, 64]               0\n",
      "       BasicBlock-34          [-1, 128, 64, 64]               0\n",
      "           Conv2d-35          [-1, 256, 32, 32]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 32, 32]             512\n",
      "             ReLU-37          [-1, 256, 32, 32]               0\n",
      "           Conv2d-38          [-1, 256, 32, 32]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 32, 32]             512\n",
      "           Conv2d-40          [-1, 256, 32, 32]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 32, 32]             512\n",
      "             ReLU-42          [-1, 256, 32, 32]               0\n",
      "       BasicBlock-43          [-1, 256, 32, 32]               0\n",
      "           Conv2d-44          [-1, 256, 32, 32]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 32, 32]             512\n",
      "             ReLU-46          [-1, 256, 32, 32]               0\n",
      "           Conv2d-47          [-1, 256, 32, 32]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 32, 32]             512\n",
      "             ReLU-49          [-1, 256, 32, 32]               0\n",
      "       BasicBlock-50          [-1, 256, 32, 32]               0\n",
      "           Conv2d-51          [-1, 512, 16, 16]       1,179,648\n",
      "      BatchNorm2d-52          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-53          [-1, 512, 16, 16]               0\n",
      "           Conv2d-54          [-1, 512, 16, 16]       2,359,296\n",
      "      BatchNorm2d-55          [-1, 512, 16, 16]           1,024\n",
      "           Conv2d-56          [-1, 512, 16, 16]         131,072\n",
      "      BatchNorm2d-57          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-58          [-1, 512, 16, 16]               0\n",
      "       BasicBlock-59          [-1, 512, 16, 16]               0\n",
      "           Conv2d-60          [-1, 512, 16, 16]       2,359,296\n",
      "      BatchNorm2d-61          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-62          [-1, 512, 16, 16]               0\n",
      "           Conv2d-63          [-1, 512, 16, 16]       2,359,296\n",
      "      BatchNorm2d-64          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-65          [-1, 512, 16, 16]               0\n",
      "       BasicBlock-66          [-1, 512, 16, 16]               0\n",
      "    ResNetEncoder-67  [[-1, 3, 512, 512], [-1, 64, 256, 256], [-1, 64, 128, 128], [-1, 128, 64, 64], [-1, 256, 32, 32], [-1, 512, 16, 16]]               0\n",
      "         Identity-68          [-1, 512, 16, 16]               0\n",
      "         Identity-69          [-1, 768, 32, 32]               0\n",
      "        Attention-70          [-1, 768, 32, 32]               0\n",
      "           Conv2d-71          [-1, 256, 32, 32]       1,769,472\n",
      "      BatchNorm2d-72          [-1, 256, 32, 32]             512\n",
      "             ReLU-73          [-1, 256, 32, 32]               0\n",
      "           Conv2d-74          [-1, 256, 32, 32]         589,824\n",
      "      BatchNorm2d-75          [-1, 256, 32, 32]             512\n",
      "             ReLU-76          [-1, 256, 32, 32]               0\n",
      "         Identity-77          [-1, 256, 32, 32]               0\n",
      "        Attention-78          [-1, 256, 32, 32]               0\n",
      "     DecoderBlock-79          [-1, 256, 32, 32]               0\n",
      "         Identity-80          [-1, 384, 64, 64]               0\n",
      "        Attention-81          [-1, 384, 64, 64]               0\n",
      "           Conv2d-82          [-1, 128, 64, 64]         442,368\n",
      "      BatchNorm2d-83          [-1, 128, 64, 64]             256\n",
      "             ReLU-84          [-1, 128, 64, 64]               0\n",
      "           Conv2d-85          [-1, 128, 64, 64]         147,456\n",
      "      BatchNorm2d-86          [-1, 128, 64, 64]             256\n",
      "             ReLU-87          [-1, 128, 64, 64]               0\n",
      "         Identity-88          [-1, 128, 64, 64]               0\n",
      "        Attention-89          [-1, 128, 64, 64]               0\n",
      "     DecoderBlock-90          [-1, 128, 64, 64]               0\n",
      "         Identity-91        [-1, 192, 128, 128]               0\n",
      "        Attention-92        [-1, 192, 128, 128]               0\n",
      "           Conv2d-93         [-1, 64, 128, 128]         110,592\n",
      "      BatchNorm2d-94         [-1, 64, 128, 128]             128\n",
      "             ReLU-95         [-1, 64, 128, 128]               0\n",
      "           Conv2d-96         [-1, 64, 128, 128]          36,864\n",
      "      BatchNorm2d-97         [-1, 64, 128, 128]             128\n",
      "             ReLU-98         [-1, 64, 128, 128]               0\n",
      "         Identity-99         [-1, 64, 128, 128]               0\n",
      "       Attention-100         [-1, 64, 128, 128]               0\n",
      "    DecoderBlock-101         [-1, 64, 128, 128]               0\n",
      "        Identity-102        [-1, 128, 256, 256]               0\n",
      "       Attention-103        [-1, 128, 256, 256]               0\n",
      "          Conv2d-104         [-1, 32, 256, 256]          36,864\n",
      "     BatchNorm2d-105         [-1, 32, 256, 256]              64\n",
      "            ReLU-106         [-1, 32, 256, 256]               0\n",
      "          Conv2d-107         [-1, 32, 256, 256]           9,216\n",
      "     BatchNorm2d-108         [-1, 32, 256, 256]              64\n",
      "            ReLU-109         [-1, 32, 256, 256]               0\n",
      "        Identity-110         [-1, 32, 256, 256]               0\n",
      "       Attention-111         [-1, 32, 256, 256]               0\n",
      "    DecoderBlock-112         [-1, 32, 256, 256]               0\n",
      "          Conv2d-113         [-1, 16, 512, 512]           4,608\n",
      "     BatchNorm2d-114         [-1, 16, 512, 512]              32\n",
      "            ReLU-115         [-1, 16, 512, 512]               0\n",
      "          Conv2d-116         [-1, 16, 512, 512]           2,304\n",
      "     BatchNorm2d-117         [-1, 16, 512, 512]              32\n",
      "            ReLU-118         [-1, 16, 512, 512]               0\n",
      "        Identity-119         [-1, 16, 512, 512]               0\n",
      "       Attention-120         [-1, 16, 512, 512]               0\n",
      "    DecoderBlock-121         [-1, 16, 512, 512]               0\n",
      "     UnetDecoder-122         [-1, 16, 512, 512]               0\n",
      "          Conv2d-123          [-1, 1, 512, 512]             145\n",
      "        Identity-124          [-1, 1, 512, 512]               0\n",
      "        Identity-125          [-1, 1, 512, 512]               0\n",
      "      Activation-126          [-1, 1, 512, 512]               0\n",
      "================================================================\n",
      "Total params: 14,328,209\n",
      "Trainable params: 14,328,209\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 3.00\n",
      "Forward/backward pass size (MB): 1139.00\n",
      "Params size (MB): 54.66\n",
      "Estimated Total Size (MB): 1196.66\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 获取用于训练的 CPU 或 GPU 设备\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# 定义模型\n",
    "model = smp.Unet(\n",
    "    encoder_name=config.encoder_model,\n",
    "    decoder_use_batchnorm=True,\n",
    "    in_channels=3,\n",
    "    classes=config.n_class,\n",
    ").to(device)\n",
    "\n",
    "# 打印模型概述\n",
    "summary(model, (3, 512, 512))\n",
    "# 定义优化器\n",
    "optimizer = eval(config.optimizer)(model.parameters(), lr=float(config.learning_rate))\n",
    "\n",
    "# 定义学习率调度器\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, patience=20, factor=0.1\n",
    ")\n",
    "\n",
    "# 定义 Dice 损失函数\n",
    "dice_loss = smp.losses.DiceLoss(smp.losses.BINARY_MODE, from_logits=True)\n",
    "\n",
    "# 定义带有标签平滑的交叉熵损失函数\n",
    "xent = smp.losses.SoftBCEWithLogitsLoss(smooth_factor=0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自定义一个损失函数 custom_loss 接受模型的预测值和目标值作为输入，通过计算二分类交叉熵和Dice loss来计算总损失，并返回总损失、二分类交叉熵和Dice loss三个值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(pred, target):\n",
    "    xent_l = xent(pred, target)\n",
    "    dice_l = dice_loss(pred, target)\n",
    "    loss = xent_l + dice_l\n",
    "    return loss, xent_l, dice_l"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接受模型和优化器作为输入，通过训练集数据计算总损失、二分类交叉熵和Dice loss，并返回这些值，以及输入图像、目标掩模和模型的预测掩模。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer):\n",
    "    # total number of training batches\n",
    "    num_batches = math.ceil(len(ds_dict[\"train_ds\"][\"img_npy\"]) / batch_size)\n",
    "    model.train()\n",
    "    batch_xent_l = []\n",
    "    batch_dice_l = []\n",
    "    batch_loss = []\n",
    "    print(\"Training...\")\n",
    "    for i in tqdm(range(num_batches)):\n",
    "        train_batch = next(train_gen)\n",
    "        imgs = train_batch[\"data\"]\n",
    "        segs = train_batch[\"seg\"]\n",
    "        # normalization\n",
    "        imgs = min_max_norm(imgs)\n",
    "        # binarisation\n",
    "        segs = np.where(segs > 0.0, 1.0, 0.0).astype(\"float32\")\n",
    "        segs = np.expand_dims(segs[:, 0, :, :], 1)\n",
    "        imgs, segs = torch.from_numpy(imgs).to(device), torch.from_numpy(segs).to(\n",
    "            device\n",
    "        )\n",
    "        # Compute loss\n",
    "        pred = model(imgs)\n",
    "        loss, xent_l, dice_l = custom_loss(pred, segs)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # batch losses\n",
    "        batch_xent_l.append(xent_l)\n",
    "        batch_dice_l.append(dice_l)\n",
    "        batch_loss.append(loss)\n",
    "    # apply sigmoid to masking\n",
    "    segs = nn.Sigmoid()(segs)\n",
    "    # taking the average along the batch\n",
    "    loss = torch.mean(torch.as_tensor(batch_loss)).item()\n",
    "    avg_xent_l = torch.mean(torch.as_tensor(batch_xent_l)).item()\n",
    "    avg_dice_l = torch.mean(torch.as_tensor(batch_dice_l)).item()\n",
    "\n",
    "    return {\n",
    "        \"loss\": loss,\n",
    "        \"xent_l\": avg_xent_l,\n",
    "        \"dice_l\": avg_dice_l,\n",
    "        \"imgs\": imgs.cpu().detach().numpy(),\n",
    "        \"segs\": segs.cpu().detach().numpy(),\n",
    "        \"pred\": pred.cpu().detach().numpy(),\n",
    "    }\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接受模型作为输入，通过测试集数据计算总损失、二分类交叉熵和Dice loss，并返回这些值，以及输入图像、目标掩模和模型的预测掩模。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    num_batches = math.ceil(len(ds_dict[\"testA_ds\"][\"img_npy\"]) / batch_size)\n",
    "    model.eval()\n",
    "    # no need back prop for testing set\n",
    "    batch_xent_l = []\n",
    "    batch_dice_l = []\n",
    "    batch_loss = []\n",
    "    print(\"Testing...\")\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(num_batches)):\n",
    "            val_batch = next(val_dl)\n",
    "            imgs = val_batch[\"data\"]\n",
    "            segs = val_batch[\"seg\"]\n",
    "            # normalization\n",
    "            imgs = min_max_norm(imgs)\n",
    "            # binarisation\n",
    "            segs = np.where(segs > 0.0, 1.0, 0.0).astype(\"float32\")\n",
    "            segs = np.expand_dims(segs[:, 0, :, :], 1)\n",
    "            imgs, segs = torch.from_numpy(imgs).to(device), torch.from_numpy(segs).to(\n",
    "                device\n",
    "            )\n",
    "            # Compute loss\n",
    "            pred = model(imgs)\n",
    "            loss, xent_l, dice_l = custom_loss(pred, segs)\n",
    "            # batch losses\n",
    "            batch_xent_l.append(xent_l)\n",
    "            batch_dice_l.append(dice_l)\n",
    "            batch_loss.append(loss)\n",
    "        # apply sigmoid to masking\n",
    "        segs = nn.Sigmoid()(segs)\n",
    "        # taking the average along the batch\n",
    "        loss = torch.mean(torch.as_tensor(batch_loss)).item()\n",
    "        avg_xent_l = torch.mean(torch.as_tensor(batch_xent_l)).item()\n",
    "        avg_dice_l = torch.mean(torch.as_tensor(batch_dice_l)).item()\n",
    "    return {\n",
    "        \"loss\": loss,\n",
    "        \"xent_l\": avg_xent_l,\n",
    "        \"dice_l\": avg_dice_l,\n",
    "        \"imgs\": imgs.cpu().detach().numpy(),\n",
    "        \"segs\": segs.cpu().detach().numpy(),\n",
    "        \"pred\": pred.cpu().detach().numpy(),\n",
    "    }\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在训练和测试函数中，首先将输入数据进行归一化和二值化处理，然后将处理后的数据转换为PyTorch张量，将其输入到模型中进行预测，并计算损失。然后使用反向传播算法计算梯度，更新模型参数。最后，将损失和其他指标取平均值，并将所有张量转换为numpy数组，以便进行可视化和进一步分析。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "主函数逻辑：\n",
    "1. 定义两个变量current_total_loss和current_dice_score，分别用于记录当前最佳的总损失值和dice得分。\n",
    "2. 对于每个epoch进行循环，从1到epochs+2。\n",
    "3. 输出当前epoch的编号。\n",
    "4. 调用train()函数进行模型训练，返回train_output，包括总损失值、二元交叉熵损失值和dice得分。\n",
    "5. 调用test()函数对模型进行测试，返回test_output，包括总损失值、二元交叉熵损失值、dice得分、模型预测输出和原始图像和标签。\n",
    "6. 调用scheduler.step()函数来更新学习率，scheduler是一个torch.optim.lr_scheduler.ReduceLROnPlateau类型的对象，用于动态调整学习率。\n",
    "7. 打印训练输出结果和验证输出结果，分别包括总损失值、二元交叉熵损失值和dice得分。\n",
    "8. 使用wandb.log()函数记录日志，包括训练集和验证集的总损失值、二元交叉熵损失值和dice得分，以及当前的学习率。\n",
    "9. 如果当前epoch是10的倍数，则进行预测可视化并使用wandb.log()函数记录可视化结果。\n",
    "10. 如果当前的验证集总损失值小于current_total_loss，则保存当前模型的参数，并将current_total_loss更新为当前验证集总损失值。同样的，如果当前dice得分大于current_dice_score，则保存当前模型的参数，并将current_dice_score更新为当前dice得分。\n",
    "11. 循环结束后，打印模型的训练时间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    start = time.time()\n",
    "    current_total_loss = 1000\n",
    "    current_dice_score = 0\n",
    "    for e in range(1, epochs + 2):\n",
    "        print(\"Epcohs:\", e)\n",
    "        train_output = train(model, optimizer)\n",
    "        test_output = test(model)\n",
    "        scheduler.step(test_output[\"loss\"])\n",
    "        print(\"Training Outputs: \")\n",
    "        print(\n",
    "            \"Total loss: {:.2f}, BCE: {:.2f}, Dice Score: {:.2f}\".format(\n",
    "                train_output[\"loss\"], train_output[\"xent_l\"], 1 - train_output[\"dice_l\"]\n",
    "            )\n",
    "        )\n",
    "        print(\"-\" * 100)\n",
    "        print(\"Validation Outputs: \")\n",
    "        print(\n",
    "            \"Total loss: {:.2f}, BCE: {:.2f}, Dice Score: {:.2f}\".format(\n",
    "                test_output[\"loss\"], test_output[\"xent_l\"], 1 - test_output[\"dice_l\"]\n",
    "            )\n",
    "        )\n",
    "        # logging\n",
    "        wandb.log(\n",
    "            {\n",
    "                \"Train_total_loss\": train_output[\"loss\"],\n",
    "                \"Val_total_loss\": test_output[\"loss\"],\n",
    "            },\n",
    "            step=e,\n",
    "        )\n",
    "        wandb.log(\n",
    "            {\n",
    "                \"Train_BCE_loss\": train_output[\"xent_l\"],\n",
    "                \"Val_BCE_loss\": test_output[\"xent_l\"],\n",
    "            },\n",
    "            step=e,\n",
    "        )\n",
    "        wandb.log(\n",
    "            {\n",
    "                \"Train_dice_score\": 1 - train_output[\"dice_l\"],\n",
    "                \"Val_dice_score\": 1 - test_output[\"dice_l\"],\n",
    "            },\n",
    "            step=e,\n",
    "        )\n",
    "        wandb.log({\"Learning rate\": optimizer.param_groups[0][\"lr\"]}, step=e)\n",
    "        if e % 10 == 0:\n",
    "            # threshold sigmoid output with 0.5\n",
    "            pred_thr = np.where(test_output[\"pred\"] > 0.5, 1.0, 0.0)\n",
    "            # sample a dataset from the batch for visualization purpose\n",
    "            imgs = [\n",
    "                test_output[\"imgs\"][0, 0, :, :],\n",
    "                test_output[\"segs\"][0, 0, :, :],\n",
    "                pred_thr[0, 0, :, :],\n",
    "            ]\n",
    "            captions = [\"Gland Image\", \"Masking\", \"Prediction\"]\n",
    "            fig = plot_comparison(\n",
    "                imgs,\n",
    "                captions,\n",
    "                plot=False,\n",
    "                n_col=len(imgs),\n",
    "                figsize=(12, 12),\n",
    "                cmap=\"gray\",\n",
    "            )\n",
    "            wandb.log({\"Validation Dataset Output Sample\": wandb.Image(fig)}, step=e)\n",
    "\n",
    "        # save model\n",
    "        weights_dir = \"./weights/\"\n",
    "        if not os.path.exists(weights_dir):\n",
    "            os.makedirs(weights_dir)\n",
    "        base_path = os.path.split(weights_dir)[0]\n",
    "        if test_output[\"loss\"] < current_total_loss:\n",
    "            current_total_loss = test_output[\"loss\"]\n",
    "            torch.save(model.state_dict(), weights_dir + \"best_loss_{}.pth\".format(e))\n",
    "            wandb.save(\n",
    "                os.path.join(weights_dir, \"best_loss_{}.pth\".format(e)),\n",
    "                base_path=base_path,\n",
    "            )\n",
    "        if (1 - test_output[\"dice_l\"]) > current_dice_score:\n",
    "            current_dice_score = 1 - test_output[\"dice_l\"]\n",
    "            torch.save(model.state_dict(), weights_dir + \"best_dice_{}.pth\".format(e))\n",
    "            wandb.save(\n",
    "                os.path.join(weights_dir, \"best_dice_{}.pth\".format(e)),\n",
    "                base_path=base_path,\n",
    "            )\n",
    "        print()\n",
    "\n",
    "    print(\"Model training runtime: {} mins\".format((time.time() - start) / 60.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epcohs: 1\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/43 [00:00<?, ?it/s]Exception in thread Thread-6 (results_loop):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Software\\Python311\\Lib\\threading.py\", line 1038, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Software\\Python311\\Lib\\threading.py\", line 975, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Software\\Python311\\Lib\\site-packages\\batchgenerators\\dataloading\\multi_threaded_augmenter.py\", line 92, in results_loop\n",
      "    raise RuntimeError(\"One or more background workers are no longer alive. Exiting. Please check the print\"\n",
      "RuntimeError: One or more background workers are no longer alive. Exiting. Please check the print statements above for the actual error message\n",
      "  0%|          | 0/43 [00:06<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "One or more background workers are no longer alive. Exiting. Please check the print statements above for the actual error message",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[18], line 7\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, epochs \u001b[39m+\u001b[39m \u001b[39m2\u001b[39m):\n\u001b[0;32m      6\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEpcohs:\u001b[39m\u001b[39m\"\u001b[39m, e)\n\u001b[1;32m----> 7\u001b[0m     train_output \u001b[39m=\u001b[39m train(model, optimizer)\n\u001b[0;32m      8\u001b[0m     test_output \u001b[39m=\u001b[39m test(model)\n\u001b[0;32m      9\u001b[0m     scheduler\u001b[39m.\u001b[39mstep(test_output[\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "Cell \u001b[1;32mIn[16], line 10\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, optimizer)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTraining...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(num_batches)):\n\u001b[1;32m---> 10\u001b[0m     train_batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(train_gen)\n\u001b[0;32m     11\u001b[0m     imgs \u001b[39m=\u001b[39m train_batch[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m     12\u001b[0m     segs \u001b[39m=\u001b[39m train_batch[\u001b[39m\"\u001b[39m\u001b[39mseg\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Software\\Python311\\Lib\\site-packages\\batchgenerators\\dataloading\\multi_threaded_augmenter.py:204\u001b[0m, in \u001b[0;36mMultiThreadedAugmenter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start()\n\u001b[0;32m    203\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 204\u001b[0m     item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_next_item()\n\u001b[0;32m    206\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39misinstance\u001b[39m(item, \u001b[39mstr\u001b[39m) \u001b[39mand\u001b[39;00m (item \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    207\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_end_ctr \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Software\\Python311\\Lib\\site-packages\\batchgenerators\\dataloading\\multi_threaded_augmenter.py:189\u001b[0m, in \u001b[0;36mMultiThreadedAugmenter.__get_next_item\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mabort_event\u001b[39m.\u001b[39mis_set():\n\u001b[0;32m    188\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_finish()\n\u001b[1;32m--> 189\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mOne or more background workers are no longer alive. Exiting. Please check the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    190\u001b[0m                        \u001b[39m\"\u001b[39m\u001b[39mprint statements above for the actual error message\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpin_memory_queue\u001b[39m.\u001b[39mempty():\n\u001b[0;32m    193\u001b[0m     item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpin_memory_queue\u001b[39m.\u001b[39mget()\n",
      "\u001b[1;31mRuntimeError\u001b[0m: One or more background workers are no longer alive. Exiting. Please check the print statements above for the actual error message"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
